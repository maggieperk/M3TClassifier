{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle5 in c:\\users\\nickh\\anaconda3\\envs\\cm2\\lib\\site-packages (0.0.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\nickh\\anaconda3\\envs\\cm2\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pickle5\n",
    "import pickle5 as pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_file(fname):\n",
    "    try:\n",
    "        data = pd.read_pickle(fname)\n",
    "    except:\n",
    "        with open(fname, \"rb\") as fh:\n",
    "            data = pickle.load(fh)\n",
    "            data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iemocap1 = load_pickle_file('iemocap_session1_af.pickle')\n",
    "# iemocap2 = load_pickle_file('iemocap_session2_af.pickle')\n",
    "# iemocap3 = load_pickle_file('iemocap_session3_af.pickle')\n",
    "# iemocap4 = load_pickle_file('iemocap_session4_af.pickle')\n",
    "# iemocap5 = load_pickle_file('iemocap_session5_af.pickle')\n",
    "\n",
    "iemocap1 = pd.read_csv('iemocap_session1_af.csv')\n",
    "iemocap1 = iemocap1.loc[:, ~iemocap1.columns.str.contains('^Unnamed')]\n",
    "iemocap2 = pd.read_csv('iemocap_session2_af.csv')\n",
    "iemocap2 = iemocap2.loc[:, ~iemocap2.columns.str.contains('^Unnamed')]\n",
    "iemocap3 = pd.read_csv('iemocap_session3_af.csv')\n",
    "iemocap3 = iemocap3.loc[:, ~iemocap3.columns.str.contains('^Unnamed')]\n",
    "iemocap4 = pd.read_csv('iemocap_session4_af.csv')\n",
    "iemocap4 = iemocap4.loc[:, ~iemocap4.columns.str.contains('^Unnamed')]\n",
    "iemocap5 = pd.read_csv('iemocap_session5_af.csv')\n",
    "iemocap5 = iemocap5.loc[:, ~iemocap5.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1XzqZtRp4Vm",
    "outputId": "7a575555-6ac0-47f6-a6e7-c6073820ae78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819\n",
      "1762\n",
      "1760\n",
      "1865\n",
      "2170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9376"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(iemocap1))\n",
    "print(len(iemocap2))\n",
    "print(len(iemocap3))\n",
    "print(len(iemocap4))\n",
    "print(len(iemocap5))\n",
    "len(iemocap1) + len(iemocap2) + len(iemocap3) + len(iemocap4) + len(iemocap5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_feature_columns = [c for c in iemocap1.columns][5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Dyv30Vd21sjg",
    "outputId": "5e0dacc4-43c7-427d-ee76-8ff5c56df0a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TURN</th>\n",
       "      <th>UTTERANCE</th>\n",
       "      <th>DA</th>\n",
       "      <th>EMOTION</th>\n",
       "      <th>audio_file</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_amean_b</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_stddevNorm_b</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_percentile20.0_b</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_percentile50.0_b</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_percentile80.0_b</th>\n",
       "      <th>...</th>\n",
       "      <th>slopeUV0-500_sma3nz_amean_e</th>\n",
       "      <th>slopeUV500-1500_sma3nz_amean_e</th>\n",
       "      <th>spectralFluxUV_sma3nz_amean_e</th>\n",
       "      <th>loudnessPeaksPerSec_e</th>\n",
       "      <th>VoicedSegmentsPerSec_e</th>\n",
       "      <th>MeanVoicedSegmentLengthSec_e</th>\n",
       "      <th>StddevVoicedSegmentLengthSec_e</th>\n",
       "      <th>MeanUnvoicedSegmentLength_e</th>\n",
       "      <th>StddevUnvoicedSegmentLength_e</th>\n",
       "      <th>equivalentSoundLevel_dBp_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses01F_impro01_F000</td>\n",
       "      <td>Excuse me.</td>\n",
       "      <td>c</td>\n",
       "      <td>neu</td>\n",
       "      <td>Ses01F_impro01_F000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>1.587302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-50.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses01F_impro01_M000</td>\n",
       "      <td>Do you have your forms?</td>\n",
       "      <td>q</td>\n",
       "      <td>fru</td>\n",
       "      <td>Ses01F_impro01_M000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009739</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.038869</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.833280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses01F_impro01_F001</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>ans</td>\n",
       "      <td>neu</td>\n",
       "      <td>Ses01F_impro01_F001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.019451</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-52.912780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses01F_impro01_M001</td>\n",
       "      <td>Let me see them.</td>\n",
       "      <td>s</td>\n",
       "      <td>fru</td>\n",
       "      <td>Ses01F_impro01_M001</td>\n",
       "      <td>26.122112</td>\n",
       "      <td>0.032891</td>\n",
       "      <td>26.099644</td>\n",
       "      <td>26.244362</td>\n",
       "      <td>26.424637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008951</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.029631</td>\n",
       "      <td>3.252032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.143710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses01F_impro01_F002</td>\n",
       "      <td>Is there a problem?</td>\n",
       "      <td>q</td>\n",
       "      <td>neu</td>\n",
       "      <td>Ses01F_impro01_F002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>2.912622</td>\n",
       "      <td>3.061225</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.123895</td>\n",
       "      <td>-32.468056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>Ses01M_script03_2_F040</td>\n",
       "      <td>This is the end do you hear me?  Finally and f...</td>\n",
       "      <td>s</td>\n",
       "      <td>ang</td>\n",
       "      <td>Ses01M_script03_2_F040</td>\n",
       "      <td>32.384240</td>\n",
       "      <td>0.081119</td>\n",
       "      <td>30.534610</td>\n",
       "      <td>31.911644</td>\n",
       "      <td>33.069565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005440</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.087855</td>\n",
       "      <td>1.234568</td>\n",
       "      <td>1.273885</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>-18.378300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>Ses01M_script03_2_M041</td>\n",
       "      <td>You're not going like this.</td>\n",
       "      <td>c</td>\n",
       "      <td>ang</td>\n",
       "      <td>Ses01M_script03_2_M041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.083328</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.428572</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-34.489544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Ses01M_script03_2_F041</td>\n",
       "      <td>Oh yes I am...Oh yes I am. Let go of me. You l...</td>\n",
       "      <td>o</td>\n",
       "      <td>ang</td>\n",
       "      <td>Ses01M_script03_2_F041</td>\n",
       "      <td>40.590290</td>\n",
       "      <td>0.169796</td>\n",
       "      <td>34.144410</td>\n",
       "      <td>40.024890</td>\n",
       "      <td>48.004020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>1.118974</td>\n",
       "      <td>2.702703</td>\n",
       "      <td>1.442308</td>\n",
       "      <td>0.491111</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.378118</td>\n",
       "      <td>-5.156447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Ses01M_script03_2_M042</td>\n",
       "      <td>No you're not.</td>\n",
       "      <td>dag</td>\n",
       "      <td>ang</td>\n",
       "      <td>Ses01M_script03_2_M042</td>\n",
       "      <td>31.108418</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>30.754486</td>\n",
       "      <td>30.995090</td>\n",
       "      <td>31.593002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022332</td>\n",
       "      <td>-0.017279</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>6.122449</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.127279</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>-22.351753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Ses01M_script03_2_M043</td>\n",
       "      <td>Shut up. Shut up. I wouldn't marry you again i...</td>\n",
       "      <td>o</td>\n",
       "      <td>ang</td>\n",
       "      <td>Ses01M_script03_2_M043</td>\n",
       "      <td>46.032696</td>\n",
       "      <td>0.099883</td>\n",
       "      <td>43.077580</td>\n",
       "      <td>45.162704</td>\n",
       "      <td>49.379196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>-0.019572</td>\n",
       "      <td>3.486527</td>\n",
       "      <td>3.797468</td>\n",
       "      <td>1.495727</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.523668</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.042295</td>\n",
       "      <td>-4.197755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows Ã— 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        TURN  \\\n",
       "0        Ses01F_impro01_F000   \n",
       "1        Ses01F_impro01_M000   \n",
       "2        Ses01F_impro01_F001   \n",
       "3        Ses01F_impro01_M001   \n",
       "4        Ses01F_impro01_F002   \n",
       "...                      ...   \n",
       "1814  Ses01M_script03_2_F040   \n",
       "1815  Ses01M_script03_2_M041   \n",
       "1816  Ses01M_script03_2_F041   \n",
       "1817  Ses01M_script03_2_M042   \n",
       "1818  Ses01M_script03_2_M043   \n",
       "\n",
       "                                              UTTERANCE   DA EMOTION  \\\n",
       "0                                            Excuse me.    c     neu   \n",
       "1                               Do you have your forms?    q     fru   \n",
       "2                                                 Yeah.  ans     neu   \n",
       "3                                      Let me see them.    s     fru   \n",
       "4                                   Is there a problem?    q     neu   \n",
       "...                                                 ...  ...     ...   \n",
       "1814  This is the end do you hear me?  Finally and f...    s     ang   \n",
       "1815                        You're not going like this.    c     ang   \n",
       "1816  Oh yes I am...Oh yes I am. Let go of me. You l...    o     ang   \n",
       "1817                                     No you're not.  dag     ang   \n",
       "1818  Shut up. Shut up. I wouldn't marry you again i...    o     ang   \n",
       "\n",
       "                  audio_file  F0semitoneFrom27.5Hz_sma3nz_amean_b  \\\n",
       "0        Ses01F_impro01_F000                             0.000000   \n",
       "1        Ses01F_impro01_M000                             0.000000   \n",
       "2        Ses01F_impro01_F001                             0.000000   \n",
       "3        Ses01F_impro01_M001                            26.122112   \n",
       "4        Ses01F_impro01_F002                             0.000000   \n",
       "...                      ...                                  ...   \n",
       "1814  Ses01M_script03_2_F040                            32.384240   \n",
       "1815  Ses01M_script03_2_M041                             0.000000   \n",
       "1816  Ses01M_script03_2_F041                            40.590290   \n",
       "1817  Ses01M_script03_2_M042                            31.108418   \n",
       "1818  Ses01M_script03_2_M043                            46.032696   \n",
       "\n",
       "      F0semitoneFrom27.5Hz_sma3nz_stddevNorm_b  \\\n",
       "0                                     0.000000   \n",
       "1                                     0.000000   \n",
       "2                                     0.000000   \n",
       "3                                     0.032891   \n",
       "4                                     0.000000   \n",
       "...                                        ...   \n",
       "1814                                  0.081119   \n",
       "1815                                  0.000000   \n",
       "1816                                  0.169796   \n",
       "1817                                  0.012443   \n",
       "1818                                  0.099883   \n",
       "\n",
       "      F0semitoneFrom27.5Hz_sma3nz_percentile20.0_b  \\\n",
       "0                                         0.000000   \n",
       "1                                         0.000000   \n",
       "2                                         0.000000   \n",
       "3                                        26.099644   \n",
       "4                                         0.000000   \n",
       "...                                            ...   \n",
       "1814                                     30.534610   \n",
       "1815                                      0.000000   \n",
       "1816                                     34.144410   \n",
       "1817                                     30.754486   \n",
       "1818                                     43.077580   \n",
       "\n",
       "      F0semitoneFrom27.5Hz_sma3nz_percentile50.0_b  \\\n",
       "0                                         0.000000   \n",
       "1                                         0.000000   \n",
       "2                                         0.000000   \n",
       "3                                        26.244362   \n",
       "4                                         0.000000   \n",
       "...                                            ...   \n",
       "1814                                     31.911644   \n",
       "1815                                      0.000000   \n",
       "1816                                     40.024890   \n",
       "1817                                     30.995090   \n",
       "1818                                     45.162704   \n",
       "\n",
       "      F0semitoneFrom27.5Hz_sma3nz_percentile80.0_b  ...  \\\n",
       "0                                         0.000000  ...   \n",
       "1                                         0.000000  ...   \n",
       "2                                         0.000000  ...   \n",
       "3                                        26.424637  ...   \n",
       "4                                         0.000000  ...   \n",
       "...                                            ...  ...   \n",
       "1814                                     33.069565  ...   \n",
       "1815                                      0.000000  ...   \n",
       "1816                                     48.004020  ...   \n",
       "1817                                     31.593002  ...   \n",
       "1818                                     49.379196  ...   \n",
       "\n",
       "      slopeUV0-500_sma3nz_amean_e  slopeUV500-1500_sma3nz_amean_e  \\\n",
       "0                       -0.000731                        0.002195   \n",
       "1                       -0.009739                        0.005470   \n",
       "2                       -0.000152                        0.001867   \n",
       "3                       -0.008951                        0.001008   \n",
       "4                        0.000056                       -0.000669   \n",
       "...                           ...                             ...   \n",
       "1814                    -0.005440                        0.003610   \n",
       "1815                     0.000795                        0.006013   \n",
       "1816                     0.016079                       -0.004743   \n",
       "1817                     0.022332                       -0.017279   \n",
       "1818                     0.022607                       -0.019572   \n",
       "\n",
       "      spectralFluxUV_sma3nz_amean_e  loudnessPeaksPerSec_e  \\\n",
       "0                          0.027680               1.587302   \n",
       "1                          0.038869               1.052632   \n",
       "2                          0.019451               8.888889   \n",
       "3                          0.029631               3.252032   \n",
       "4                          0.037681               2.912622   \n",
       "...                             ...                    ...   \n",
       "1814                       0.087855               1.234568   \n",
       "1815                       0.083328               2.666667   \n",
       "1816                       1.118974               2.702703   \n",
       "1817                       0.420517               3.571429   \n",
       "1818                       3.486527               3.797468   \n",
       "\n",
       "      VoicedSegmentsPerSec_e  MeanVoicedSegmentLengthSec_e  \\\n",
       "0                   0.000000                      0.000000   \n",
       "1                   1.111111                      0.270000   \n",
       "2                   0.000000                      0.000000   \n",
       "3                   0.000000                      0.000000   \n",
       "4                   3.061225                      0.143333   \n",
       "...                      ...                           ...   \n",
       "1814                1.273885                      0.205000   \n",
       "1815                1.428572                      0.070000   \n",
       "1816                1.442308                      0.491111   \n",
       "1817                6.122449                      0.110000   \n",
       "1818                1.495727                      0.590000   \n",
       "\n",
       "      StddevVoicedSegmentLengthSec_e  MeanUnvoicedSegmentLength_e  \\\n",
       "0                           0.000000                     0.570000   \n",
       "1                           0.000000                     0.610000   \n",
       "2                           0.000000                     0.390000   \n",
       "3                           0.000000                     1.170000   \n",
       "4                           0.004714                     0.120000   \n",
       "...                              ...                          ...   \n",
       "1814                        0.175000                     0.560000   \n",
       "1815                        0.000000                     0.300000   \n",
       "1816                        0.364583                     0.203750   \n",
       "1817                        0.127279                     0.033333   \n",
       "1818                        0.523668                     0.066667   \n",
       "\n",
       "      StddevUnvoicedSegmentLength_e  equivalentSoundLevel_dBp_e  \n",
       "0                          0.000000                  -50.019608  \n",
       "1                          0.000000                  -29.833280  \n",
       "2                          0.000000                  -52.912780  \n",
       "3                          0.000000                  -49.143710  \n",
       "4                          0.123895                  -32.468056  \n",
       "...                             ...                         ...  \n",
       "1814                       0.520000                  -18.378300  \n",
       "1815                       0.080000                  -34.489544  \n",
       "1816                       0.378118                   -5.156447  \n",
       "1817                       0.009428                  -22.351753  \n",
       "1818                       0.042295                   -4.197755  \n",
       "\n",
       "[1819 rows x 269 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocap1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DA labels\n",
    "da_labels_iemocap1 = iemocap1['DA']\n",
    "da_labels_iemocap2 = iemocap2['DA']\n",
    "da_labels_iemocap3 = iemocap3['DA']\n",
    "da_labels_iemocap4 = iemocap4['DA']\n",
    "da_labels_iemocap5 = iemocap5['DA']\n",
    "\n",
    "# Emotion labels\n",
    "emot_labels_iemocap1 = iemocap1['EMOTION']\n",
    "emot_labels_iemocap2 = iemocap2['EMOTION']\n",
    "emot_labels_iemocap3 = iemocap3['EMOTION']\n",
    "emot_labels_iemocap4 = iemocap4['EMOTION']\n",
    "emot_labels_iemocap5 = iemocap5['EMOTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s      2170\n",
       "o      2073\n",
       "q      1945\n",
       "ans    1429\n",
       "ag      497\n",
       "dag     372\n",
       "c       350\n",
       "b       284\n",
       "ap       75\n",
       "oth      68\n",
       "g        59\n",
       "a        54\n",
       "Name: DA, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sense of the value counts for the data\n",
    "full_da_labels = pd.concat([da_labels_iemocap1, da_labels_iemocap2, da_labels_iemocap3, da_labels_iemocap4, da_labels_iemocap5])\n",
    "full_da_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xxx    2305\n",
       "fru    1714\n",
       "neu    1613\n",
       "ang    1034\n",
       "sad    1011\n",
       "exc     999\n",
       "hap     563\n",
       "sur      94\n",
       "fea      38\n",
       "oth       3\n",
       "dis       2\n",
       "Name: EMOTION, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_emot_data = pd.concat([emot_labels_iemocap1, emot_labels_iemocap2, emot_labels_iemocap3, emot_labels_iemocap4, emot_labels_iemocap5])\n",
    "full_emot_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfnPtGvu1OSU",
    "outputId": "12aa201c-f4f1-4e25-bb25-8bf56a5b9e10"
   },
   "outputs": [],
   "source": [
    "# Turn code into categorical data\n",
    "# Create one hot embeddings of the label values (0, 1, 2)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Full set of dialogue act labels\n",
    "da_labels = ['s', 'q', 'o', 'ans', 'c', 'ag', 'b', 'dag', 'oth', 'a', 'ap', 'g']\n",
    "da_encoder = preprocessing.LabelEncoder()\n",
    "da_encoder.fit(da_labels)\n",
    "\n",
    "emotion_labels = ['xxx', 'fru', 'neu', 'ang', 'sad', 'exc', 'hap', 'sur', 'fea', 'oth', 'dis']\n",
    "emotion_encoder = preprocessing.LabelEncoder()\n",
    "emotion_encoder.fit(emotion_labels)\n",
    "\n",
    "def convert_da_labels_to_categorical(dialog_acts):\n",
    "    num_labels = da_encoder.transform(dialog_acts)\n",
    "    cat_labels = to_categorical(num_labels)\n",
    "    return cat_labels\n",
    "\n",
    "def convert_cat_da_to_string(cat_das):\n",
    "    num_labels = np.argmax(cat_das, axis=-1)\n",
    "    return da_encoder.inverse_transform(num_labels)\n",
    "\n",
    "def convert_emot_labels_to_categorical(emot_data):\n",
    "    num_labels = emotion_encoder.transform(emot_data)\n",
    "    cat_labels = to_categorical(num_labels)\n",
    "    return cat_labels\n",
    "\n",
    "def convert_cat_emot_to_string(cat_emot_data):\n",
    "    num_labels = np.argmax(cat_emot_data, axis=-1)\n",
    "    return emotion_encoder.inverse_transform(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "c\n",
      "neu\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "neu\n"
     ]
    }
   ],
   "source": [
    "print(da_labels_iemocap1[0])\n",
    "cat_1_labels = convert_da_labels_to_categorical(da_labels_iemocap1)\n",
    "print(cat_1_labels[0])\n",
    "string_das = convert_cat_da_to_string(cat_1_labels)\n",
    "print(string_das[0])\n",
    "\n",
    "print(emot_labels_iemocap1[0])\n",
    "cat_1_emot_labels = convert_emot_labels_to_categorical(emot_labels_iemocap1)\n",
    "print(cat_1_emot_labels[0])\n",
    "string_emot = convert_cat_emot_to_string(cat_1_emot_labels)\n",
    "print(string_emot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iemocap2[acoustic_feature_columns].to_numpy()\n",
    "y_da = convert_da_labels_to_categorical(iemocap2['DA'])\n",
    "y_emot = convert_emot_labels_to_categorical(iemocap2['EMOTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input, Model, Sequential\n",
    "from tensorflow.python.keras.layers.core import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_and_train_model(X, y_da):\n",
    "    callback = EarlyStopping(monitor='loss', patience=5)\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(256, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(len(y_da[0]), activation=\"softmax\"))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X, y_da, batch_size=32, epochs=100, validation_split=0.2, callbacks=[callback])\n",
    "    return (model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 56.4021 - accuracy: 0.1902 - val_loss: 15.3711 - val_accuracy: 0.2526\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 9.9808 - accuracy: 0.1929 - val_loss: 23.6678 - val_accuracy: 0.2242\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 3.5629 - accuracy: 0.1735 - val_loss: 19.2215 - val_accuracy: 0.2070\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.6921 - accuracy: 0.2253 - val_loss: 12.0347 - val_accuracy: 0.2083\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.1805 - accuracy: 0.2323 - val_loss: 15.0707 - val_accuracy: 0.2057\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9934 - accuracy: 0.2376 - val_loss: 14.2382 - val_accuracy: 0.2077\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9522 - accuracy: 0.2420 - val_loss: 11.3156 - val_accuracy: 0.2070\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9624 - accuracy: 0.2440 - val_loss: 11.6185 - val_accuracy: 0.2116\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9294 - accuracy: 0.2395 - val_loss: 9.8368 - val_accuracy: 0.2050\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9413 - accuracy: 0.2425 - val_loss: 9.0075 - val_accuracy: 0.2149\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9189 - accuracy: 0.2462 - val_loss: 12.3517 - val_accuracy: 0.2282\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9120 - accuracy: 0.2476 - val_loss: 11.7362 - val_accuracy: 0.2295\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9038 - accuracy: 0.2448 - val_loss: 12.2321 - val_accuracy: 0.2130\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9002 - accuracy: 0.2564 - val_loss: 11.9580 - val_accuracy: 0.2090\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9007 - accuracy: 0.2500 - val_loss: 13.3264 - val_accuracy: 0.2321\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8911 - accuracy: 0.2506 - val_loss: 13.3587 - val_accuracy: 0.2454\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8860 - accuracy: 0.2541 - val_loss: 14.6627 - val_accuracy: 0.2553\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9545 - accuracy: 0.2501 - val_loss: 4.1720 - val_accuracy: 0.2454\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.0020 - accuracy: 0.2557 - val_loss: 31.6423 - val_accuracy: 0.2507\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9115 - accuracy: 0.2501 - val_loss: 32.2279 - val_accuracy: 0.2427\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8842 - accuracy: 0.2516 - val_loss: 32.2049 - val_accuracy: 0.2302\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8823 - accuracy: 0.2615 - val_loss: 32.8034 - val_accuracy: 0.2533\n",
      "Epoch 23/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8805 - accuracy: 0.2630 - val_loss: 22.6809 - val_accuracy: 0.2500\n",
      "Epoch 24/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8813 - accuracy: 0.2602 - val_loss: 23.7081 - val_accuracy: 0.2526\n",
      "Epoch 25/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8701 - accuracy: 0.2589 - val_loss: 20.4607 - val_accuracy: 0.2348\n",
      "Epoch 26/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8736 - accuracy: 0.2562 - val_loss: 19.7832 - val_accuracy: 0.2579\n",
      "Epoch 27/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8836 - accuracy: 0.2581 - val_loss: 19.4514 - val_accuracy: 0.2242\n",
      "Epoch 28/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8697 - accuracy: 0.2625 - val_loss: 20.7427 - val_accuracy: 0.2361\n",
      "Epoch 29/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8744 - accuracy: 0.2519 - val_loss: 13.0068 - val_accuracy: 0.2315\n",
      "Epoch 30/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8717 - accuracy: 0.2581 - val_loss: 18.1450 - val_accuracy: 0.2520\n",
      "Epoch 31/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8774 - accuracy: 0.2569 - val_loss: 20.8161 - val_accuracy: 0.2606\n",
      "Epoch 32/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8722 - accuracy: 0.2546 - val_loss: 17.9224 - val_accuracy: 0.2626\n",
      "Epoch 33/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8635 - accuracy: 0.2680 - val_loss: 17.5193 - val_accuracy: 0.2467\n",
      "Epoch 34/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8707 - accuracy: 0.2670 - val_loss: 21.4369 - val_accuracy: 0.2507\n",
      "Epoch 35/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8668 - accuracy: 0.2587 - val_loss: 19.2284 - val_accuracy: 0.2388\n",
      "Epoch 36/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8620 - accuracy: 0.2630 - val_loss: 19.9940 - val_accuracy: 0.2606\n",
      "Epoch 37/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8669 - accuracy: 0.2625 - val_loss: 23.9013 - val_accuracy: 0.2513\n",
      "Epoch 38/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8724 - accuracy: 0.2605 - val_loss: 20.0656 - val_accuracy: 0.2586\n",
      "Epoch 39/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8738 - accuracy: 0.2652 - val_loss: 19.4373 - val_accuracy: 0.2407\n",
      "Epoch 40/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8576 - accuracy: 0.2648 - val_loss: 17.7400 - val_accuracy: 0.2440\n",
      "Epoch 41/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8585 - accuracy: 0.2672 - val_loss: 17.3673 - val_accuracy: 0.2454\n",
      "Epoch 42/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8589 - accuracy: 0.2657 - val_loss: 17.2850 - val_accuracy: 0.2606\n",
      "Epoch 43/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8545 - accuracy: 0.2617 - val_loss: 18.4279 - val_accuracy: 0.2447\n",
      "Epoch 44/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8780 - accuracy: 0.2605 - val_loss: 20.6594 - val_accuracy: 0.2685\n",
      "Epoch 45/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9097 - accuracy: 0.2665 - val_loss: 12.3242 - val_accuracy: 0.2560\n",
      "Epoch 46/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8819 - accuracy: 0.2600 - val_loss: 16.1720 - val_accuracy: 0.2679\n",
      "Epoch 47/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.8681 - accuracy: 0.2562 - val_loss: 13.2975 - val_accuracy: 0.2507\n",
      "Epoch 48/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9075 - accuracy: 0.2607 - val_loss: 12.2039 - val_accuracy: 0.2626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x2af8792d5c8>,\n",
       " <keras.callbacks.History at 0x2af89baa9c8>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_and_train_model(X, y_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 6, ..., 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model1.predict(X)\n",
    "\n",
    "#preds = [np.argmax(pred) for pred in preds]\n",
    "#pd.DataFrame(data=np.array(preds)).value_counts()\n",
    "\n",
    "np.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1762, 264)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test fold assignments\n",
    "\n",
    "tr1 = pd.concat([iemocap1, iemocap2, iemocap3, iemocap4])\n",
    "te1 = iemocap5\n",
    "\n",
    "tr2 = pd.concat([iemocap1, iemocap2, iemocap3, iemocap5])\n",
    "te2 = iemocap4\n",
    "\n",
    "tr3 = pd.concat([iemocap1, iemocap2, iemocap4, iemocap5])\n",
    "te3 = iemocap3\n",
    "\n",
    "tr4 = pd.concat([iemocap1, iemocap3, iemocap4, iemocap5])\n",
    "te4 = iemocap2\n",
    "\n",
    "tr5 = pd.concat([iemocap2, iemocap3, iemocap4, iemocap5])\n",
    "te5 = iemocap1\n",
    "\n",
    "splits = [(tr1, te1), (tr2, te2), (tr3, te3), (tr4, te4), (tr5, te5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 56.2348 - accuracy: 0.1855 - val_loss: 8.7620 - val_accuracy: 0.2254\n",
      "Epoch 2/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 4.8024 - accuracy: 0.2071 - val_loss: 3.4275 - val_accuracy: 0.2469\n",
      "Epoch 3/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.6345 - accuracy: 0.2361 - val_loss: 3.0733 - val_accuracy: 0.2476\n",
      "Epoch 4/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.2679 - accuracy: 0.2403 - val_loss: 2.9988 - val_accuracy: 0.2483\n",
      "Epoch 5/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.1879 - accuracy: 0.2380 - val_loss: 2.8970 - val_accuracy: 0.2476\n",
      "Epoch 6/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.1224 - accuracy: 0.2384 - val_loss: 2.8514 - val_accuracy: 0.2476\n",
      "Epoch 7/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.0709 - accuracy: 0.2387 - val_loss: 2.7076 - val_accuracy: 0.2483\n",
      "Epoch 8/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.0406 - accuracy: 0.2385 - val_loss: 2.6882 - val_accuracy: 0.2483\n",
      "Epoch 9/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.0174 - accuracy: 0.2370 - val_loss: 2.6469 - val_accuracy: 0.2476\n",
      "Epoch 10/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.0038 - accuracy: 0.2385 - val_loss: 2.6466 - val_accuracy: 0.2476\n",
      "Epoch 11/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 2.0330 - accuracy: 0.2377 - val_loss: 2.7524 - val_accuracy: 0.2476\n",
      "Epoch 12/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9829 - accuracy: 0.2380 - val_loss: 2.6272 - val_accuracy: 0.2476\n",
      "Epoch 13/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9785 - accuracy: 0.2391 - val_loss: 2.6560 - val_accuracy: 0.2476\n",
      "Epoch 14/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9766 - accuracy: 0.2384 - val_loss: 2.6475 - val_accuracy: 0.2476\n",
      "Epoch 15/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9648 - accuracy: 0.2392 - val_loss: 2.5684 - val_accuracy: 0.2476\n",
      "Epoch 16/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9623 - accuracy: 0.2384 - val_loss: 2.5129 - val_accuracy: 0.2476\n",
      "Epoch 17/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9547 - accuracy: 0.2387 - val_loss: 2.5228 - val_accuracy: 0.2476\n",
      "Epoch 18/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9577 - accuracy: 0.2387 - val_loss: 2.5347 - val_accuracy: 0.2483\n",
      "Epoch 19/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9503 - accuracy: 0.2387 - val_loss: 2.5413 - val_accuracy: 0.2483\n",
      "Epoch 20/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9487 - accuracy: 0.2387 - val_loss: 2.5448 - val_accuracy: 0.2483\n",
      "Epoch 21/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9519 - accuracy: 0.2389 - val_loss: 2.5846 - val_accuracy: 0.2476\n",
      "Epoch 22/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9504 - accuracy: 0.2391 - val_loss: 2.5974 - val_accuracy: 0.2476\n",
      "Epoch 23/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9772 - accuracy: 0.2384 - val_loss: 2.7096 - val_accuracy: 0.2476\n",
      "Epoch 24/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9491 - accuracy: 0.2385 - val_loss: 2.5656 - val_accuracy: 0.2476\n",
      "Epoch 25/100\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.9562 - accuracy: 0.2385 - val_loss: 2.4162 - val_accuracy: 0.2483\n",
      "Epoch 1/100\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 51.7268 - accuracy: 0.1786 - val_loss: 36.3727 - val_accuracy: 0.2196\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 7.7262 - accuracy: 0.1904 - val_loss: 24.0589 - val_accuracy: 0.1989\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.7163 - accuracy: 0.2180 - val_loss: 10.8694 - val_accuracy: 0.2036\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.3261 - accuracy: 0.2190 - val_loss: 6.2422 - val_accuracy: 0.2016\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.2088 - accuracy: 0.2270 - val_loss: 9.1749 - val_accuracy: 0.2089\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.1187 - accuracy: 0.2272 - val_loss: 10.8414 - val_accuracy: 0.2116\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.0906 - accuracy: 0.2267 - val_loss: 8.6942 - val_accuracy: 0.2076\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.0427 - accuracy: 0.2237 - val_loss: 6.8308 - val_accuracy: 0.2063\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.0417 - accuracy: 0.2202 - val_loss: 16.3506 - val_accuracy: 0.2076\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.0207 - accuracy: 0.2329 - val_loss: 13.1590 - val_accuracy: 0.2076\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9958 - accuracy: 0.2342 - val_loss: 13.9880 - val_accuracy: 0.2076\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9897 - accuracy: 0.2324 - val_loss: 14.7565 - val_accuracy: 0.2069\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9791 - accuracy: 0.2330 - val_loss: 14.2480 - val_accuracy: 0.2069\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9742 - accuracy: 0.2337 - val_loss: 15.3640 - val_accuracy: 0.2063\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9748 - accuracy: 0.2332 - val_loss: 15.9268 - val_accuracy: 0.2063\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9799 - accuracy: 0.2322 - val_loss: 15.5427 - val_accuracy: 0.2063\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9653 - accuracy: 0.2337 - val_loss: 14.8327 - val_accuracy: 0.2063\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9606 - accuracy: 0.2329 - val_loss: 15.7132 - val_accuracy: 0.2063\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9620 - accuracy: 0.2339 - val_loss: 15.8629 - val_accuracy: 0.2063\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9576 - accuracy: 0.2332 - val_loss: 15.8677 - val_accuracy: 0.2063\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9596 - accuracy: 0.2334 - val_loss: 15.2639 - val_accuracy: 0.2063\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9609 - accuracy: 0.2327 - val_loss: 10.4656 - val_accuracy: 0.2063\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9571 - accuracy: 0.2329 - val_loss: 11.1104 - val_accuracy: 0.2063\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9652 - accuracy: 0.2334 - val_loss: 13.0278 - val_accuracy: 0.2063\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9600 - accuracy: 0.2339 - val_loss: 12.2817 - val_accuracy: 0.2063\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9574 - accuracy: 0.2337 - val_loss: 11.3027 - val_accuracy: 0.2063\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9649 - accuracy: 0.2334 - val_loss: 10.6095 - val_accuracy: 0.2063\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9558 - accuracy: 0.2335 - val_loss: 10.7693 - val_accuracy: 0.2063\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9580 - accuracy: 0.2332 - val_loss: 10.4577 - val_accuracy: 0.2063\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9622 - accuracy: 0.2329 - val_loss: 10.4139 - val_accuracy: 0.2043\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9596 - accuracy: 0.2332 - val_loss: 10.0942 - val_accuracy: 0.2063\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9585 - accuracy: 0.2325 - val_loss: 2.9764 - val_accuracy: 0.2063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9556 - accuracy: 0.2327 - val_loss: 2.4574 - val_accuracy: 0.2063\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9552 - accuracy: 0.2329 - val_loss: 2.5865 - val_accuracy: 0.2063\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9561 - accuracy: 0.2329 - val_loss: 2.2540 - val_accuracy: 0.2063\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9569 - accuracy: 0.2332 - val_loss: 2.5273 - val_accuracy: 0.2063\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9568 - accuracy: 0.2329 - val_loss: 2.5686 - val_accuracy: 0.2063\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9561 - accuracy: 0.2327 - val_loss: 2.5658 - val_accuracy: 0.2063\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9577 - accuracy: 0.2325 - val_loss: 2.4997 - val_accuracy: 0.2063\n",
      "Epoch 1/100\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 50.4202 - accuracy: 0.1944 - val_loss: 36.0139 - val_accuracy: 0.2283\n",
      "Epoch 2/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 8.0776 - accuracy: 0.2017 - val_loss: 4.3092 - val_accuracy: 0.2054\n",
      "Epoch 3/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 3.6687 - accuracy: 0.2406 - val_loss: 2.9517 - val_accuracy: 0.2329\n",
      "Epoch 4/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.8913 - accuracy: 0.2398 - val_loss: 2.4439 - val_accuracy: 0.2283\n",
      "Epoch 5/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.6719 - accuracy: 0.2405 - val_loss: 37.8869 - val_accuracy: 0.2474\n",
      "Epoch 6/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.3301 - accuracy: 0.2544 - val_loss: 60.1191 - val_accuracy: 0.2139\n",
      "Epoch 7/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.1770 - accuracy: 0.2564 - val_loss: 58.3547 - val_accuracy: 0.2323\n",
      "Epoch 8/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.0763 - accuracy: 0.2531 - val_loss: 59.9971 - val_accuracy: 0.2244\n",
      "Epoch 9/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.0876 - accuracy: 0.2556 - val_loss: 49.1903 - val_accuracy: 0.2152\n",
      "Epoch 10/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.0049 - accuracy: 0.2574 - val_loss: 46.3078 - val_accuracy: 0.2520\n",
      "Epoch 11/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9873 - accuracy: 0.2666 - val_loss: 53.5583 - val_accuracy: 0.2526\n",
      "Epoch 12/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9429 - accuracy: 0.2613 - val_loss: 49.3607 - val_accuracy: 0.2402\n",
      "Epoch 13/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9334 - accuracy: 0.2626 - val_loss: 47.6419 - val_accuracy: 0.2362\n",
      "Epoch 14/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9425 - accuracy: 0.2554 - val_loss: 49.7164 - val_accuracy: 0.2395\n",
      "Epoch 15/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9363 - accuracy: 0.2577 - val_loss: 48.4274 - val_accuracy: 0.2349\n",
      "Epoch 16/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9263 - accuracy: 0.2689 - val_loss: 52.6639 - val_accuracy: 0.2356\n",
      "Epoch 17/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9222 - accuracy: 0.2561 - val_loss: 59.3991 - val_accuracy: 0.2382\n",
      "Epoch 18/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9372 - accuracy: 0.2666 - val_loss: 57.1191 - val_accuracy: 0.2421\n",
      "Epoch 19/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9307 - accuracy: 0.2631 - val_loss: 63.3483 - val_accuracy: 0.2343\n",
      "Epoch 20/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9108 - accuracy: 0.2644 - val_loss: 68.2065 - val_accuracy: 0.2493\n",
      "Epoch 21/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9270 - accuracy: 0.2636 - val_loss: 69.1409 - val_accuracy: 0.2408\n",
      "Epoch 22/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9050 - accuracy: 0.2623 - val_loss: 68.0669 - val_accuracy: 0.2323\n",
      "Epoch 23/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9050 - accuracy: 0.2646 - val_loss: 65.4752 - val_accuracy: 0.2428\n",
      "Epoch 24/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9161 - accuracy: 0.2608 - val_loss: 56.3488 - val_accuracy: 0.2146\n",
      "Epoch 25/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9234 - accuracy: 0.2457 - val_loss: 56.4669 - val_accuracy: 0.2093\n",
      "Epoch 26/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9377 - accuracy: 0.2443 - val_loss: 62.7744 - val_accuracy: 0.2270\n",
      "Epoch 27/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9438 - accuracy: 0.2469 - val_loss: 54.4161 - val_accuracy: 0.2119\n",
      "Epoch 1/100\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 47.6681 - accuracy: 0.1877 - val_loss: 35.7221 - val_accuracy: 0.2246\n",
      "Epoch 2/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 6.9738 - accuracy: 0.2014 - val_loss: 24.1170 - val_accuracy: 0.2055\n",
      "Epoch 3/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.6500 - accuracy: 0.2318 - val_loss: 18.3685 - val_accuracy: 0.2055\n",
      "Epoch 4/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.3181 - accuracy: 0.2369 - val_loss: 24.6718 - val_accuracy: 0.2068\n",
      "Epoch 5/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.2246 - accuracy: 0.2366 - val_loss: 27.1574 - val_accuracy: 0.2055\n",
      "Epoch 6/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.0735 - accuracy: 0.2369 - val_loss: 26.3484 - val_accuracy: 0.2068\n",
      "Epoch 7/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.0324 - accuracy: 0.2381 - val_loss: 27.0170 - val_accuracy: 0.2055\n",
      "Epoch 8/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.0978 - accuracy: 0.2363 - val_loss: 19.7241 - val_accuracy: 0.2068\n",
      "Epoch 9/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 2.0049 - accuracy: 0.2372 - val_loss: 18.3735 - val_accuracy: 0.2081\n",
      "Epoch 10/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9703 - accuracy: 0.2384 - val_loss: 19.1982 - val_accuracy: 0.2055\n",
      "Epoch 11/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9690 - accuracy: 0.2382 - val_loss: 20.2882 - val_accuracy: 0.2075\n",
      "Epoch 12/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9660 - accuracy: 0.2379 - val_loss: 18.9600 - val_accuracy: 0.2075\n",
      "Epoch 13/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9720 - accuracy: 0.2371 - val_loss: 17.0567 - val_accuracy: 0.2081\n",
      "Epoch 14/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9643 - accuracy: 0.2363 - val_loss: 17.3834 - val_accuracy: 0.2081\n",
      "Epoch 15/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9445 - accuracy: 0.2381 - val_loss: 14.3717 - val_accuracy: 0.2068\n",
      "Epoch 16/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9398 - accuracy: 0.2377 - val_loss: 13.9395 - val_accuracy: 0.2081\n",
      "Epoch 17/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9385 - accuracy: 0.2379 - val_loss: 14.3439 - val_accuracy: 0.2075\n",
      "Epoch 18/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9307 - accuracy: 0.2379 - val_loss: 14.9895 - val_accuracy: 0.2068\n",
      "Epoch 19/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9380 - accuracy: 0.2376 - val_loss: 15.2545 - val_accuracy: 0.2075\n",
      "Epoch 20/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9361 - accuracy: 0.2382 - val_loss: 19.0837 - val_accuracy: 0.2068\n",
      "Epoch 21/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9511 - accuracy: 0.2379 - val_loss: 21.9208 - val_accuracy: 0.2068\n",
      "Epoch 22/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9393 - accuracy: 0.2389 - val_loss: 12.2031 - val_accuracy: 0.2068\n",
      "Epoch 23/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9304 - accuracy: 0.2381 - val_loss: 10.9891 - val_accuracy: 0.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9960 - accuracy: 0.2384 - val_loss: 6.5588 - val_accuracy: 0.2055\n",
      "Epoch 25/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9291 - accuracy: 0.2387 - val_loss: 6.7068 - val_accuracy: 0.2055\n",
      "Epoch 26/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9267 - accuracy: 0.2381 - val_loss: 3.7629 - val_accuracy: 0.2068\n",
      "Epoch 27/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9268 - accuracy: 0.2384 - val_loss: 4.8065 - val_accuracy: 0.2068\n",
      "Epoch 28/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9235 - accuracy: 0.2382 - val_loss: 4.2733 - val_accuracy: 0.2068\n",
      "Epoch 29/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9255 - accuracy: 0.2384 - val_loss: 5.3274 - val_accuracy: 0.2068\n",
      "Epoch 30/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9240 - accuracy: 0.2385 - val_loss: 5.3188 - val_accuracy: 0.2068\n",
      "Epoch 31/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9240 - accuracy: 0.2389 - val_loss: 7.5963 - val_accuracy: 0.2068\n",
      "Epoch 32/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9292 - accuracy: 0.2387 - val_loss: 7.5286 - val_accuracy: 0.2068\n",
      "Epoch 33/100\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1.9248 - accuracy: 0.2384 - val_loss: 8.2392 - val_accuracy: 0.2055\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 56.9686 - accuracy: 0.1863 - val_loss: 25.3196 - val_accuracy: 0.2024\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 5.2164 - accuracy: 0.2132 - val_loss: 19.0690 - val_accuracy: 0.2044\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.4335 - accuracy: 0.2390 - val_loss: 23.2364 - val_accuracy: 0.2057\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.2455 - accuracy: 0.2417 - val_loss: 20.9230 - val_accuracy: 0.2050\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.1220 - accuracy: 0.2410 - val_loss: 24.5012 - val_accuracy: 0.2050\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.0730 - accuracy: 0.2404 - val_loss: 18.4815 - val_accuracy: 0.2050\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.0391 - accuracy: 0.2428 - val_loss: 22.4113 - val_accuracy: 0.2050\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.0032 - accuracy: 0.2417 - val_loss: 22.7805 - val_accuracy: 0.2050\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9940 - accuracy: 0.2414 - val_loss: 23.1680 - val_accuracy: 0.2050\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9756 - accuracy: 0.2427 - val_loss: 23.7969 - val_accuracy: 0.2050\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9897 - accuracy: 0.2425 - val_loss: 21.4422 - val_accuracy: 0.2050\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9505 - accuracy: 0.2423 - val_loss: 21.1125 - val_accuracy: 0.2050\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.0180 - accuracy: 0.2414 - val_loss: 23.7018 - val_accuracy: 0.2057\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9830 - accuracy: 0.2419 - val_loss: 23.1022 - val_accuracy: 0.2050\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9367 - accuracy: 0.2423 - val_loss: 23.1515 - val_accuracy: 0.2050\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9311 - accuracy: 0.2417 - val_loss: 23.0848 - val_accuracy: 0.2050\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9318 - accuracy: 0.2422 - val_loss: 22.7847 - val_accuracy: 0.2050\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9317 - accuracy: 0.2420 - val_loss: 24.3681 - val_accuracy: 0.2050\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9480 - accuracy: 0.2414 - val_loss: 30.4070 - val_accuracy: 0.2050\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9302 - accuracy: 0.2417 - val_loss: 27.4933 - val_accuracy: 0.2050\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9387 - accuracy: 0.2417 - val_loss: 21.1842 - val_accuracy: 0.2057\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9270 - accuracy: 0.2415 - val_loss: 21.0732 - val_accuracy: 0.2057\n",
      "Epoch 23/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9241 - accuracy: 0.2415 - val_loss: 21.0501 - val_accuracy: 0.2063\n",
      "Epoch 24/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9241 - accuracy: 0.2415 - val_loss: 21.0885 - val_accuracy: 0.2063\n",
      "Epoch 25/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9260 - accuracy: 0.2414 - val_loss: 20.1360 - val_accuracy: 0.2063\n",
      "Epoch 26/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9267 - accuracy: 0.2417 - val_loss: 20.3788 - val_accuracy: 0.2057\n",
      "Epoch 27/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9263 - accuracy: 0.2417 - val_loss: 21.4785 - val_accuracy: 0.2050\n",
      "Epoch 28/100\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9246 - accuracy: 0.2412 - val_loss: 20.7483 - val_accuracy: 0.2057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for s in splits:\n",
    "    tr, te = s\n",
    "    X_train = tr[acoustic_feature_columns].to_numpy()\n",
    "    y_train = convert_da_labels_to_categorical(tr['DA'])\n",
    "    X_test = te[acoustic_feature_columns].to_numpy()\n",
    "    y_test = convert_da_labels_to_categorical(te['DA'])\n",
    "    model, history = build_and_train_model(X_train, y_train)\n",
    "    \n",
    "    preds = np.argmax(model.predict(X_test), axis=1)\n",
    "    y_uni = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    y_pred += preds.tolist()\n",
    "    y_true += y_uni.tolist()\n",
    "    \n",
    "    p = precision_score(y_uni, preds, average='micro')\n",
    "    r = recall_score(y_uni, preds, average='micro')\n",
    "    f1 = f1_score(y_uni, preds, average='micro')\n",
    "    \n",
    "    precision_scores.append(p)\n",
    "    recall_scores.append(r)\n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205991</td>\n",
       "      <td>0.205991</td>\n",
       "      <td>0.205991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.251475</td>\n",
       "      <td>0.251475</td>\n",
       "      <td>0.251475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236932</td>\n",
       "      <td>0.236932</td>\n",
       "      <td>0.236932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242338</td>\n",
       "      <td>0.242338</td>\n",
       "      <td>0.242338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.224299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision    Recall        F1\n",
       "0   0.205991  0.205991  0.205991\n",
       "1   0.251475  0.251475  0.251475\n",
       "2   0.236932  0.236932  0.236932\n",
       "3   0.242338  0.242338  0.242338\n",
       "4   0.224299  0.224299  0.224299"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data=zip(precision_scores, recall_scores, f1_scores), columns=['Precision', 'Recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.247325</td>\n",
       "      <td>0.247325</td>\n",
       "      <td>0.247325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025091</td>\n",
       "      <td>0.025091</td>\n",
       "      <td>0.025091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.205991</td>\n",
       "      <td>0.205991</td>\n",
       "      <td>0.205991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.242441</td>\n",
       "      <td>0.242441</td>\n",
       "      <td>0.242441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.257094</td>\n",
       "      <td>0.257094</td>\n",
       "      <td>0.257094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.261932</td>\n",
       "      <td>0.261932</td>\n",
       "      <td>0.261932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.269169</td>\n",
       "      <td>0.269169</td>\n",
       "      <td>0.269169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision    Recall        F1\n",
       "count   5.000000  5.000000  5.000000\n",
       "mean    0.247325  0.247325  0.247325\n",
       "std     0.025091  0.025091  0.025091\n",
       "min     0.205991  0.205991  0.205991\n",
       "25%     0.242441  0.242441  0.242441\n",
       "50%     0.257094  0.257094  0.257094\n",
       "75%     0.261932  0.261932  0.261932\n",
       "max     0.269169  0.269169  0.269169"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        54\n",
      "           1       0.00      0.00      0.00       497\n",
      "           2       0.18      0.00      0.00      1429\n",
      "           3       0.00      0.00      0.00        75\n",
      "           4       0.00      0.00      0.00       284\n",
      "           5       0.00      0.00      0.00       350\n",
      "           6       0.00      0.00      0.00       372\n",
      "           7       0.00      0.00      0.00        59\n",
      "           8       0.08      0.00      0.00      2073\n",
      "           9       0.17      0.04      0.07        68\n",
      "          10       0.11      0.00      0.00      1945\n",
      "          11       0.23      0.99      0.38      2170\n",
      "\n",
      "    accuracy                           0.23      9376\n",
      "   macro avg       0.06      0.09      0.04      9376\n",
      "weighted avg       0.12      0.23      0.09      9376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickh\\anaconda3\\envs\\cm2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nickh\\anaconda3\\envs\\cm2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nickh\\anaconda3\\envs\\cm2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cr = classification_report(y_true, y_pred)\n",
    "print(cr)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=da_labels, columns=da_labels)\n",
    "\n",
    "ax = sn.heatmap(df_cm, cmap='Blues', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    2170\n",
       "8     2073\n",
       "10    1945\n",
       "2     1429\n",
       "1      497\n",
       "6      372\n",
       "5      350\n",
       "4      284\n",
       "3       75\n",
       "9       68\n",
       "7       59\n",
       "0       54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_true).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    9302\n",
       "9       18\n",
       "10      18\n",
       "2       17\n",
       "8       13\n",
       "1        3\n",
       "4        2\n",
       "6        2\n",
       "5        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).value_counts()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FinalProject_DeepLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
